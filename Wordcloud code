!pip install lxml
!pip install wordcloud
!pip install nltk
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
%matplotlib inline

import seaborn as sns

from sklearn import (linear_model, metrics, neural_network, pipeline, preprocessing, model_selection)

from bs4 import BeautifulSoup
import nltk
import string
from nltk.tokenize import RegexpTokenizer
from nltk.tokenize import word_tokenize
nltk.download('stopwords')
nltk.download('wordnet')

from wordcloud import WordCloud

types = pd.read_csv("MBTI_type.csv")
posts = pd.read_csv("MBTI_posts.csv")

sep_posts = posts['posts'].str.split("\|\|\|", expand = True)

def shift(row):
    row = row.dropna()
    row = pd.Series(row.values)
    return row

def remove_first_apostrophe(s):
    if s[0] == "'":
        post = s[1:]
    else:
        post = s
    return post

sep_posts = sep_posts.apply(lambda x: x.str.strip()).replace('', np.nan).dropna(how='all', axis=1)
sep_posts2 = sep_posts.apply(shift, axis = 1)



sep_posts2[0] = sep_posts2[0].apply(remove_first_apostrophe)
sep_posts2.iloc[:, -1] = sep_posts2.iloc[:, -1].apply(lambda x: x[:-1] if isinstance(x, str) else x)
sample_posts = pd.DataFrame(sep_posts2[0])


data_wc = pd.concat([types, sample_posts], axis=1)
data_wc.columns = ['type', 'posts']

data_wc['favorite world'] = data_wc['type'].apply(lambda x: 'Extrovert' if x[0] == 'E' else 'Introvert')
data_wc['information'] = data_wc['type'].apply(lambda x: 'Intuitive' if x[1] == 'N' else 'Sensing')
data_wc['decisions'] = data_wc['type'].apply(lambda x: 'Thinking' if x[2] == 'T' else 'Feeling')
data_wc['structure'] = data_wc['type'].apply(lambda x: 'Judging' if x[3] == 'J' else 'Perceiving')

# Remove stopwords using the 'english' library which includes words such as (the, a, an, is, to)
stopwords = set(nltk.corpus.stopwords.words('english'))
stopwords = stopwords.union(set(string.punctuation))
wnl = nltk.WordNetLemmatizer()

# Defining a function that cleans, tokenizes, removes stopwords, and lemmatizes words in a text
def text_prep(txt):
    soup = BeautifulSoup(txt, "lxml")
    [s.extract() for s in soup('style')]
    txt=soup.text
    txt = txt.lower()
    tokens = [token for token in nltk.tokenize.word_tokenize(txt)]
    tokens = [token for token in tokens if not token in stopwords]
    tokens = [wnl.lemmatize(token) for token in tokens]
    if (len(tokens)==0):
        tokens = ["EMPTYSTRING"]
    return(tokens)

# Defining a function that generates wordcloud
def gen_wc(posts, title):
    wordcloud = WordCloud(background_color='white', max_words=100).generate(posts)
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title(title)
    plt.show()

letter = ["Extrovert", "Introvert", "Intuitive", "Sensing", "Thinking", "Feeling", "Judging", "Perceiving"]
types = ["favorite world", "favorite world", "information", "information", "decisions", "decisions", "structure", "structure"]

# Wordcloud for the 8 indicators of MBTI personality type
for l, t in zip(letter, types):
    text = pd.Series(' '.join(data_wc.groupby(f"{t}")['posts'].get_group(f"{l}")).split()).to_string(index = False)
    text = text_prep(text)
    text_str = ' '.join(text)
    wordcloud = WordCloud(collocations = False, background_color='white', max_words=200).generate(text_str)
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.title(f"{l}")
    plt.show()

